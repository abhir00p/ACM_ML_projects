{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5943a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f78687",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c500b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Petal_width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal_length  Sepal_width  Petal_length  Petal_width      Species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5           5.4          3.9           1.7          0.4  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"iris.csv\")\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f518b2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sepal_length  Sepal_width  Petal_length  Petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b4a87f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Sepal_length  150 non-null    float64\n",
      " 1   Sepal_width   150 non-null    float64\n",
      " 2   Petal_length  150 non-null    float64\n",
      " 3   Petal_width   150 non-null    float64\n",
      " 4   Species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e650542",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "The target variable is in string form this needs to be converted to numeric form to be used for deep learning therefore we use lable encoder. Then we convert the dataframe to numpyarray which is required for Keras deep learning. We then seperate the feature and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcf42f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labl = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60a979e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Petal_width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal_length  Sepal_width  Petal_length  Petal_width  Species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Species'] = labl.fit_transform(df['Species'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8418cb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ],\n",
       "       [5.4, 3.9, 1.7, 0.4, 0. ],\n",
       "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
       "       [5. , 3.4, 1.5, 0.2, 0. ],\n",
       "       [4.4, 2.9, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5.4, 3.7, 1.5, 0.2, 0. ],\n",
       "       [4.8, 3.4, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
       "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
       "       [5.8, 4. , 1.2, 0.2, 0. ],\n",
       "       [5.7, 4.4, 1.5, 0.4, 0. ],\n",
       "       [5.4, 3.9, 1.3, 0.4, 0. ],\n",
       "       [5.1, 3.5, 1.4, 0.3, 0. ],\n",
       "       [5.7, 3.8, 1.7, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.5, 0.3, 0. ],\n",
       "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
       "       [5.1, 3.7, 1.5, 0.4, 0. ],\n",
       "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
       "       [5.1, 3.3, 1.7, 0.5, 0. ],\n",
       "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
       "       [5. , 3. , 1.6, 0.2, 0. ],\n",
       "       [5. , 3.4, 1.6, 0.4, 0. ],\n",
       "       [5.2, 3.5, 1.5, 0.2, 0. ],\n",
       "       [5.2, 3.4, 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
       "       [5.4, 3.4, 1.5, 0.4, 0. ],\n",
       "       [5.2, 4.1, 1.5, 0.1, 0. ],\n",
       "       [5.5, 4.2, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5. , 3.2, 1.2, 0.2, 0. ],\n",
       "       [5.5, 3.5, 1.3, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [4.4, 3. , 1.3, 0.2, 0. ],\n",
       "       [5.1, 3.4, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
       "       [4.5, 2.3, 1.3, 0.3, 0. ],\n",
       "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.6, 0.6, 0. ],\n",
       "       [5.1, 3.8, 1.9, 0.4, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.6, 0.2, 0. ],\n",
       "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
       "       [5.3, 3.7, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.3, 1.4, 0.2, 0. ],\n",
       "       [7. , 3.2, 4.7, 1.4, 1. ],\n",
       "       [6.4, 3.2, 4.5, 1.5, 1. ],\n",
       "       [6.9, 3.1, 4.9, 1.5, 1. ],\n",
       "       [5.5, 2.3, 4. , 1.3, 1. ],\n",
       "       [6.5, 2.8, 4.6, 1.5, 1. ],\n",
       "       [5.7, 2.8, 4.5, 1.3, 1. ],\n",
       "       [6.3, 3.3, 4.7, 1.6, 1. ],\n",
       "       [4.9, 2.4, 3.3, 1. , 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4, 1. ],\n",
       "       [5. , 2. , 3.5, 1. , 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5, 1. ],\n",
       "       [6. , 2.2, 4. , 1. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4, 1. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1. ],\n",
       "       [6.7, 3.1, 4.4, 1.4, 1. ],\n",
       "       [5.6, 3. , 4.5, 1.5, 1. ],\n",
       "       [5.8, 2.7, 4.1, 1. , 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5, 1. ],\n",
       "       [5.6, 2.5, 3.9, 1.1, 1. ],\n",
       "       [5.9, 3.2, 4.8, 1.8, 1. ],\n",
       "       [6.1, 2.8, 4. , 1.3, 1. ],\n",
       "       [6.3, 2.5, 4.9, 1.5, 1. ],\n",
       "       [6.1, 2.8, 4.7, 1.2, 1. ],\n",
       "       [6.4, 2.9, 4.3, 1.3, 1. ],\n",
       "       [6.6, 3. , 4.4, 1.4, 1. ],\n",
       "       [6.8, 2.8, 4.8, 1.4, 1. ],\n",
       "       [6.7, 3. , 5. , 1.7, 1. ],\n",
       "       [6. , 2.9, 4.5, 1.5, 1. ],\n",
       "       [5.7, 2.6, 3.5, 1. , 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1, 1. ],\n",
       "       [5.5, 2.4, 3.7, 1. , 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2, 1. ],\n",
       "       [6. , 2.7, 5.1, 1.6, 1. ],\n",
       "       [5.4, 3. , 4.5, 1.5, 1. ],\n",
       "       [6. , 3.4, 4.5, 1.6, 1. ],\n",
       "       [6.7, 3.1, 4.7, 1.5, 1. ],\n",
       "       [6.3, 2.3, 4.4, 1.3, 1. ],\n",
       "       [5.6, 3. , 4.1, 1.3, 1. ],\n",
       "       [5.5, 2.5, 4. , 1.3, 1. ],\n",
       "       [5.5, 2.6, 4.4, 1.2, 1. ],\n",
       "       [6.1, 3. , 4.6, 1.4, 1. ],\n",
       "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
       "       [5. , 2.3, 3.3, 1. , 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3, 1. ],\n",
       "       [5.7, 3. , 4.2, 1.2, 1. ],\n",
       "       [5.7, 2.9, 4.2, 1.3, 1. ],\n",
       "       [6.2, 2.9, 4.3, 1.3, 1. ],\n",
       "       [5.1, 2.5, 3. , 1.1, 1. ],\n",
       "       [5.7, 2.8, 4.1, 1.3, 1. ],\n",
       "       [6.3, 3.3, 6. , 2.5, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [7.1, 3. , 5.9, 2.1, 2. ],\n",
       "       [6.3, 2.9, 5.6, 1.8, 2. ],\n",
       "       [6.5, 3. , 5.8, 2.2, 2. ],\n",
       "       [7.6, 3. , 6.6, 2.1, 2. ],\n",
       "       [4.9, 2.5, 4.5, 1.7, 2. ],\n",
       "       [7.3, 2.9, 6.3, 1.8, 2. ],\n",
       "       [6.7, 2.5, 5.8, 1.8, 2. ],\n",
       "       [7.2, 3.6, 6.1, 2.5, 2. ],\n",
       "       [6.5, 3.2, 5.1, 2. , 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9, 2. ],\n",
       "       [6.8, 3. , 5.5, 2.1, 2. ],\n",
       "       [5.7, 2.5, 5. , 2. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4, 2. ],\n",
       "       [6.4, 3.2, 5.3, 2.3, 2. ],\n",
       "       [6.5, 3. , 5.5, 1.8, 2. ],\n",
       "       [7.7, 3.8, 6.7, 2.2, 2. ],\n",
       "       [7.7, 2.6, 6.9, 2.3, 2. ],\n",
       "       [6. , 2.2, 5. , 1.5, 2. ],\n",
       "       [6.9, 3.2, 5.7, 2.3, 2. ],\n",
       "       [5.6, 2.8, 4.9, 2. , 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. , 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.1, 2. ],\n",
       "       [7.2, 3.2, 6. , 1.8, 2. ],\n",
       "       [6.2, 2.8, 4.8, 1.8, 2. ],\n",
       "       [6.1, 3. , 4.9, 1.8, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.1, 2. ],\n",
       "       [7.2, 3. , 5.8, 1.6, 2. ],\n",
       "       [7.4, 2.8, 6.1, 1.9, 2. ],\n",
       "       [7.9, 3.8, 6.4, 2. , 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2, 2. ],\n",
       "       [6.3, 2.8, 5.1, 1.5, 2. ],\n",
       "       [6.1, 2.6, 5.6, 1.4, 2. ],\n",
       "       [7.7, 3. , 6.1, 2.3, 2. ],\n",
       "       [6.3, 3.4, 5.6, 2.4, 2. ],\n",
       "       [6.4, 3.1, 5.5, 1.8, 2. ],\n",
       "       [6. , 3. , 4.8, 1.8, 2. ],\n",
       "       [6.9, 3.1, 5.4, 2.1, 2. ],\n",
       "       [6.7, 3.1, 5.6, 2.4, 2. ],\n",
       "       [6.9, 3.1, 5.1, 2.3, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [6.8, 3.2, 5.9, 2.3, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.5, 2. ],\n",
       "       [6.7, 3. , 5.2, 2.3, 2. ],\n",
       "       [6.3, 2.5, 5. , 1.9, 2. ],\n",
       "       [6.5, 3. , 5.2, 2. , 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3, 2. ],\n",
       "       [5.9, 3. , 5.1, 1.8, 2. ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_npy = df.to_numpy()\n",
    "df_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "339d350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = df_npy[:,0:4]\n",
    "y_data=df_npy[:,4]\n",
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d67459e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597fcb8",
   "metadata": {},
   "source": [
    "## Scaling the data. \n",
    "As each column might be on different scales so we need to standerdize the scaling.Here I will standardize features by removing the mean and scaling to unit variance.Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data(mean=0,std_varience=1).The ultimate goal to perform standardization is to bring down all the features to a common scale without distorting the differences in the range of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12685a9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.00681170e-01,  1.03205722e+00, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.14301691e+00, -1.24957601e-01, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.38535265e+00,  3.37848329e-01, -1.39813811e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.50652052e+00,  1.06445364e-01, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00,  1.26346019e+00, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-5.37177559e-01,  1.95766909e+00, -1.17067529e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-1.50652052e+00,  8.00654259e-01, -1.34127240e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-1.02184904e+00,  8.00654259e-01, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.74885626e+00, -3.56360566e-01, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.14301691e+00,  1.06445364e-01, -1.28440670e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-5.37177559e-01,  1.49486315e+00, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.26418478e+00,  8.00654259e-01, -1.22754100e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.26418478e+00, -1.24957601e-01, -1.34127240e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-1.87002413e+00, -1.24957601e-01, -1.51186952e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-5.25060772e-02,  2.18907205e+00, -1.45500381e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.73673948e-01,  3.11468391e+00, -1.28440670e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-5.37177559e-01,  1.95766909e+00, -1.39813811e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-9.00681170e-01,  1.03205722e+00, -1.34127240e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-1.73673948e-01,  1.72626612e+00, -1.17067529e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-9.00681170e-01,  1.72626612e+00, -1.28440670e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-5.37177559e-01,  8.00654259e-01, -1.17067529e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-9.00681170e-01,  1.49486315e+00, -1.28440670e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-1.50652052e+00,  1.26346019e+00, -1.56873522e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-9.00681170e-01,  5.69251294e-01, -1.17067529e+00,\n",
       "        -9.18557817e-01],\n",
       "       [-1.26418478e+00,  8.00654259e-01, -1.05694388e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00, -1.24957601e-01, -1.22754100e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00,  8.00654259e-01, -1.22754100e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-7.79513300e-01,  1.03205722e+00, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-7.79513300e-01,  8.00654259e-01, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.38535265e+00,  3.37848329e-01, -1.22754100e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.26418478e+00,  1.06445364e-01, -1.22754100e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-5.37177559e-01,  8.00654259e-01, -1.28440670e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-7.79513300e-01,  2.42047502e+00, -1.28440670e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-4.16009689e-01,  2.65187798e+00, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.14301691e+00,  1.06445364e-01, -1.28440670e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-1.02184904e+00,  3.37848329e-01, -1.45500381e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-4.16009689e-01,  1.03205722e+00, -1.39813811e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.14301691e+00,  1.06445364e-01, -1.28440670e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-1.74885626e+00, -1.24957601e-01, -1.39813811e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-9.00681170e-01,  8.00654259e-01, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00,  1.03205722e+00, -1.39813811e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-1.62768839e+00, -1.74477836e+00, -1.39813811e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-1.74885626e+00,  3.37848329e-01, -1.39813811e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00,  1.03205722e+00, -1.22754100e+00,\n",
       "        -7.87084847e-01],\n",
       "       [-9.00681170e-01,  1.72626612e+00, -1.05694388e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-1.26418478e+00, -1.24957601e-01, -1.34127240e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-9.00681170e-01,  1.72626612e+00, -1.22754100e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.50652052e+00,  3.37848329e-01, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-6.58345429e-01,  1.49486315e+00, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00,  5.69251294e-01, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [ 1.40150837e+00,  3.37848329e-01,  5.35295827e-01,\n",
       "         2.64698913e-01],\n",
       "       [ 6.74501145e-01,  3.37848329e-01,  4.21564419e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 1.28034050e+00,  1.06445364e-01,  6.49027235e-01,\n",
       "         3.96171883e-01],\n",
       "       [-4.16009689e-01, -1.74477836e+00,  1.37235899e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 7.95669016e-01, -5.87763531e-01,  4.78430123e-01,\n",
       "         3.96171883e-01],\n",
       "       [-1.73673948e-01, -5.87763531e-01,  4.21564419e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 5.53333275e-01,  5.69251294e-01,  5.35295827e-01,\n",
       "         5.27644853e-01],\n",
       "       [-1.14301691e+00, -1.51337539e+00, -2.60824029e-01,\n",
       "        -2.61192967e-01],\n",
       "       [ 9.16836886e-01, -3.56360566e-01,  4.78430123e-01,\n",
       "         1.33225943e-01],\n",
       "       [-7.79513300e-01, -8.19166497e-01,  8.03701950e-02,\n",
       "         2.64698913e-01],\n",
       "       [-1.02184904e+00, -2.43898725e+00, -1.47092621e-01,\n",
       "        -2.61192967e-01],\n",
       "       [ 6.86617933e-02, -1.24957601e-01,  2.50967307e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 1.89829664e-01, -1.97618132e+00,  1.37235899e-01,\n",
       "        -2.61192967e-01],\n",
       "       [ 3.10997534e-01, -3.56360566e-01,  5.35295827e-01,\n",
       "         2.64698913e-01],\n",
       "       [-2.94841818e-01, -3.56360566e-01, -9.02269170e-02,\n",
       "         1.33225943e-01],\n",
       "       [ 1.03800476e+00,  1.06445364e-01,  3.64698715e-01,\n",
       "         2.64698913e-01],\n",
       "       [-2.94841818e-01, -1.24957601e-01,  4.21564419e-01,\n",
       "         3.96171883e-01],\n",
       "       [-5.25060772e-02, -8.19166497e-01,  1.94101603e-01,\n",
       "        -2.61192967e-01],\n",
       "       [ 4.32165405e-01, -1.97618132e+00,  4.21564419e-01,\n",
       "         3.96171883e-01],\n",
       "       [-2.94841818e-01, -1.28197243e+00,  8.03701950e-02,\n",
       "        -1.29719997e-01],\n",
       "       [ 6.86617933e-02,  3.37848329e-01,  5.92161531e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 3.10997534e-01, -5.87763531e-01,  1.37235899e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 5.53333275e-01, -1.28197243e+00,  6.49027235e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 3.10997534e-01, -5.87763531e-01,  5.35295827e-01,\n",
       "         1.75297293e-03],\n",
       "       [ 6.74501145e-01, -3.56360566e-01,  3.07833011e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 9.16836886e-01, -1.24957601e-01,  3.64698715e-01,\n",
       "         2.64698913e-01],\n",
       "       [ 1.15917263e+00, -5.87763531e-01,  5.92161531e-01,\n",
       "         2.64698913e-01],\n",
       "       [ 1.03800476e+00, -1.24957601e-01,  7.05892939e-01,\n",
       "         6.59117823e-01],\n",
       "       [ 1.89829664e-01, -3.56360566e-01,  4.21564419e-01,\n",
       "         3.96171883e-01],\n",
       "       [-1.73673948e-01, -1.05056946e+00, -1.47092621e-01,\n",
       "        -2.61192967e-01],\n",
       "       [-4.16009689e-01, -1.51337539e+00,  2.35044910e-02,\n",
       "        -1.29719997e-01],\n",
       "       [-4.16009689e-01, -1.51337539e+00, -3.33612130e-02,\n",
       "        -2.61192967e-01],\n",
       "       [-5.25060772e-02, -8.19166497e-01,  8.03701950e-02,\n",
       "         1.75297293e-03],\n",
       "       [ 1.89829664e-01, -8.19166497e-01,  7.62758643e-01,\n",
       "         5.27644853e-01],\n",
       "       [-5.37177559e-01, -1.24957601e-01,  4.21564419e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 1.89829664e-01,  8.00654259e-01,  4.21564419e-01,\n",
       "         5.27644853e-01],\n",
       "       [ 1.03800476e+00,  1.06445364e-01,  5.35295827e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 5.53333275e-01, -1.74477836e+00,  3.64698715e-01,\n",
       "         1.33225943e-01],\n",
       "       [-2.94841818e-01, -1.24957601e-01,  1.94101603e-01,\n",
       "         1.33225943e-01],\n",
       "       [-4.16009689e-01, -1.28197243e+00,  1.37235899e-01,\n",
       "         1.33225943e-01],\n",
       "       [-4.16009689e-01, -1.05056946e+00,  3.64698715e-01,\n",
       "         1.75297293e-03],\n",
       "       [ 3.10997534e-01, -1.24957601e-01,  4.78430123e-01,\n",
       "         2.64698913e-01],\n",
       "       [-5.25060772e-02, -1.05056946e+00,  1.37235899e-01,\n",
       "         1.75297293e-03],\n",
       "       [-1.02184904e+00, -1.74477836e+00, -2.60824029e-01,\n",
       "        -2.61192967e-01],\n",
       "       [-2.94841818e-01, -8.19166497e-01,  2.50967307e-01,\n",
       "         1.33225943e-01],\n",
       "       [-1.73673948e-01, -1.24957601e-01,  2.50967307e-01,\n",
       "         1.75297293e-03],\n",
       "       [-1.73673948e-01, -3.56360566e-01,  2.50967307e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 4.32165405e-01, -3.56360566e-01,  3.07833011e-01,\n",
       "         1.33225943e-01],\n",
       "       [-9.00681170e-01, -1.28197243e+00, -4.31421141e-01,\n",
       "        -1.29719997e-01],\n",
       "       [-1.73673948e-01, -5.87763531e-01,  1.94101603e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 5.53333275e-01,  5.69251294e-01,  1.27454998e+00,\n",
       "         1.71090158e+00],\n",
       "       [-5.25060772e-02, -8.19166497e-01,  7.62758643e-01,\n",
       "         9.22063763e-01],\n",
       "       [ 1.52267624e+00, -1.24957601e-01,  1.21768427e+00,\n",
       "         1.18500970e+00],\n",
       "       [ 5.53333275e-01, -3.56360566e-01,  1.04708716e+00,\n",
       "         7.90590793e-01],\n",
       "       [ 7.95669016e-01, -1.24957601e-01,  1.16081857e+00,\n",
       "         1.31648267e+00],\n",
       "       [ 2.12851559e+00, -1.24957601e-01,  1.61574420e+00,\n",
       "         1.18500970e+00],\n",
       "       [-1.14301691e+00, -1.28197243e+00,  4.21564419e-01,\n",
       "         6.59117823e-01],\n",
       "       [ 1.76501198e+00, -3.56360566e-01,  1.44514709e+00,\n",
       "         7.90590793e-01],\n",
       "       [ 1.03800476e+00, -1.28197243e+00,  1.16081857e+00,\n",
       "         7.90590793e-01],\n",
       "       [ 1.64384411e+00,  1.26346019e+00,  1.33141568e+00,\n",
       "         1.71090158e+00],\n",
       "       [ 7.95669016e-01,  3.37848329e-01,  7.62758643e-01,\n",
       "         1.05353673e+00],\n",
       "       [ 6.74501145e-01, -8.19166497e-01,  8.76490051e-01,\n",
       "         9.22063763e-01],\n",
       "       [ 1.15917263e+00, -1.24957601e-01,  9.90221459e-01,\n",
       "         1.18500970e+00],\n",
       "       [-1.73673948e-01, -1.28197243e+00,  7.05892939e-01,\n",
       "         1.05353673e+00],\n",
       "       [-5.25060772e-02, -5.87763531e-01,  7.62758643e-01,\n",
       "         1.57942861e+00],\n",
       "       [ 6.74501145e-01,  3.37848329e-01,  8.76490051e-01,\n",
       "         1.44795564e+00],\n",
       "       [ 7.95669016e-01, -1.24957601e-01,  9.90221459e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 2.24968346e+00,  1.72626612e+00,  1.67260991e+00,\n",
       "         1.31648267e+00],\n",
       "       [ 2.24968346e+00, -1.05056946e+00,  1.78634131e+00,\n",
       "         1.44795564e+00],\n",
       "       [ 1.89829664e-01, -1.97618132e+00,  7.05892939e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 1.28034050e+00,  3.37848329e-01,  1.10395287e+00,\n",
       "         1.44795564e+00],\n",
       "       [-2.94841818e-01, -5.87763531e-01,  6.49027235e-01,\n",
       "         1.05353673e+00],\n",
       "       [ 2.24968346e+00, -5.87763531e-01,  1.67260991e+00,\n",
       "         1.05353673e+00],\n",
       "       [ 5.53333275e-01, -8.19166497e-01,  6.49027235e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 1.03800476e+00,  5.69251294e-01,  1.10395287e+00,\n",
       "         1.18500970e+00],\n",
       "       [ 1.64384411e+00,  3.37848329e-01,  1.27454998e+00,\n",
       "         7.90590793e-01],\n",
       "       [ 4.32165405e-01, -5.87763531e-01,  5.92161531e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 3.10997534e-01, -1.24957601e-01,  6.49027235e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 6.74501145e-01, -5.87763531e-01,  1.04708716e+00,\n",
       "         1.18500970e+00],\n",
       "       [ 1.64384411e+00, -1.24957601e-01,  1.16081857e+00,\n",
       "         5.27644853e-01],\n",
       "       [ 1.88617985e+00, -5.87763531e-01,  1.33141568e+00,\n",
       "         9.22063763e-01],\n",
       "       [ 2.49201920e+00,  1.72626612e+00,  1.50201279e+00,\n",
       "         1.05353673e+00],\n",
       "       [ 6.74501145e-01, -5.87763531e-01,  1.04708716e+00,\n",
       "         1.31648267e+00],\n",
       "       [ 5.53333275e-01, -5.87763531e-01,  7.62758643e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 3.10997534e-01, -1.05056946e+00,  1.04708716e+00,\n",
       "         2.64698913e-01],\n",
       "       [ 2.24968346e+00, -1.24957601e-01,  1.33141568e+00,\n",
       "         1.44795564e+00],\n",
       "       [ 5.53333275e-01,  8.00654259e-01,  1.04708716e+00,\n",
       "         1.57942861e+00],\n",
       "       [ 6.74501145e-01,  1.06445364e-01,  9.90221459e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 1.89829664e-01, -1.24957601e-01,  5.92161531e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 1.28034050e+00,  1.06445364e-01,  9.33355755e-01,\n",
       "         1.18500970e+00],\n",
       "       [ 1.03800476e+00,  1.06445364e-01,  1.04708716e+00,\n",
       "         1.57942861e+00],\n",
       "       [ 1.28034050e+00,  1.06445364e-01,  7.62758643e-01,\n",
       "         1.44795564e+00],\n",
       "       [-5.25060772e-02, -8.19166497e-01,  7.62758643e-01,\n",
       "         9.22063763e-01],\n",
       "       [ 1.15917263e+00,  3.37848329e-01,  1.21768427e+00,\n",
       "         1.44795564e+00],\n",
       "       [ 1.03800476e+00,  5.69251294e-01,  1.10395287e+00,\n",
       "         1.71090158e+00],\n",
       "       [ 1.03800476e+00, -1.24957601e-01,  8.19624347e-01,\n",
       "         1.44795564e+00],\n",
       "       [ 5.53333275e-01, -1.28197243e+00,  7.05892939e-01,\n",
       "         9.22063763e-01],\n",
       "       [ 7.95669016e-01, -1.24957601e-01,  8.19624347e-01,\n",
       "         1.05353673e+00],\n",
       "       [ 4.32165405e-01,  8.00654259e-01,  9.33355755e-01,\n",
       "         1.44795564e+00],\n",
       "       [ 6.86617933e-02, -1.24957601e-01,  7.62758643e-01,\n",
       "         7.90590793e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_data)\n",
    "X_data = scaler.transform(X_data)\n",
    "X_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470bb061",
   "metadata": {},
   "source": [
    "## One-hot encoding target variables\n",
    "In one-hot encoding, each unique category value is assigned a unique integer code, and then the integer code is converted into a binary vector that is all zeros. to-categorical function is used for one-hot encoding categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a2dea6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = tf.keras.utils.to_categorical(y_data,3)\n",
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9552d2",
   "metadata": {},
   "source": [
    "## Splitting data into training and test dataset\n",
    "Spliting the dataset into training and test datasets. 20% of the data set is allocated for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79e20692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split( X_data, y_data, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab1d51",
   "metadata": {},
   "source": [
    "## Defining a model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf5d95",
   "metadata": {},
   "source": [
    "Sequential is a class which is used for creating linear stack of layers in neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9548b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e217454f",
   "metadata": {},
   "source": [
    "Now I added layers to the model.Here I used 2 Dense layer with 10 neurons and used a rectified linear unit activation(\"relu\").\n",
    "The third line the the output layer it has 3 neurons and is using a softmax activation function. The model has two hidden layer and one output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "733ff520",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, input_shape=(4,), activation='relu', name='Layer_1'))\n",
    "model.add(keras.layers.Dense(10, activation='relu', name='Layer_2'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5586c473",
   "metadata": {},
   "source": [
    "Now I compiled the model using optimizer(Adam) with learning rate of 0.001. In the loss parameter I used 'categorical_crossentropy'. Loss tells how weel is th emodel learning during traning.In metrics I used 'accuracy' it mesures how many sample are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86e61112",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer,loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e89ba2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Layer_1 (Dense)             (None, 10)                50        \n",
      "                                                                 \n",
      " Layer_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d84ad8c",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Now I will train the mode. Here I used a Batch_size of 5 it means the model will update its weight after processing 5 traning samples.Here I use 50 epochs. Epochs means the number of times the traning data is used to update the model weight. I set the validation split to 20% it means 20% of the data will be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "577a28bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 - 1s - loss: 1.2557 - accuracy: 0.2917 - val_loss: 1.1723 - val_accuracy: 0.3750 - 712ms/epoch - 36ms/step\n",
      "Epoch 2/50\n",
      "20/20 - 0s - loss: 1.1061 - accuracy: 0.3958 - val_loss: 1.0092 - val_accuracy: 0.4167 - 65ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "20/20 - 0s - loss: 0.9918 - accuracy: 0.4896 - val_loss: 0.8850 - val_accuracy: 0.5833 - 60ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "20/20 - 0s - loss: 0.9103 - accuracy: 0.5625 - val_loss: 0.7914 - val_accuracy: 0.6667 - 60ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "20/20 - 0s - loss: 0.8457 - accuracy: 0.5938 - val_loss: 0.7157 - val_accuracy: 0.7500 - 49ms/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "20/20 - 0s - loss: 0.7934 - accuracy: 0.6042 - val_loss: 0.6587 - val_accuracy: 0.7917 - 50ms/epoch - 3ms/step\n",
      "Epoch 7/50\n",
      "20/20 - 0s - loss: 0.7475 - accuracy: 0.6146 - val_loss: 0.6074 - val_accuracy: 0.8333 - 52ms/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "20/20 - 0s - loss: 0.7075 - accuracy: 0.6146 - val_loss: 0.5634 - val_accuracy: 0.8333 - 49ms/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "20/20 - 0s - loss: 0.6716 - accuracy: 0.6458 - val_loss: 0.5253 - val_accuracy: 0.8333 - 49ms/epoch - 2ms/step\n",
      "Epoch 10/50\n",
      "20/20 - 0s - loss: 0.6377 - accuracy: 0.6979 - val_loss: 0.4899 - val_accuracy: 0.8333 - 56ms/epoch - 3ms/step\n",
      "Epoch 11/50\n",
      "20/20 - 0s - loss: 0.6086 - accuracy: 0.7396 - val_loss: 0.4629 - val_accuracy: 0.8333 - 49ms/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "20/20 - 0s - loss: 0.5815 - accuracy: 0.7812 - val_loss: 0.4371 - val_accuracy: 0.8333 - 52ms/epoch - 3ms/step\n",
      "Epoch 13/50\n",
      "20/20 - 0s - loss: 0.5574 - accuracy: 0.8021 - val_loss: 0.4159 - val_accuracy: 0.8333 - 51ms/epoch - 3ms/step\n",
      "Epoch 14/50\n",
      "20/20 - 0s - loss: 0.5346 - accuracy: 0.8333 - val_loss: 0.3963 - val_accuracy: 0.8333 - 48ms/epoch - 2ms/step\n",
      "Epoch 15/50\n",
      "20/20 - 0s - loss: 0.5141 - accuracy: 0.8542 - val_loss: 0.3805 - val_accuracy: 0.8333 - 48ms/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "20/20 - 0s - loss: 0.4952 - accuracy: 0.8542 - val_loss: 0.3683 - val_accuracy: 0.8750 - 78ms/epoch - 4ms/step\n",
      "Epoch 17/50\n",
      "20/20 - 0s - loss: 0.4768 - accuracy: 0.8542 - val_loss: 0.3526 - val_accuracy: 0.8750 - 51ms/epoch - 3ms/step\n",
      "Epoch 18/50\n",
      "20/20 - 0s - loss: 0.4590 - accuracy: 0.8542 - val_loss: 0.3406 - val_accuracy: 0.8750 - 48ms/epoch - 2ms/step\n",
      "Epoch 19/50\n",
      "20/20 - 0s - loss: 0.4424 - accuracy: 0.8646 - val_loss: 0.3312 - val_accuracy: 0.9167 - 48ms/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "20/20 - 0s - loss: 0.4270 - accuracy: 0.8854 - val_loss: 0.3180 - val_accuracy: 0.9167 - 54ms/epoch - 3ms/step\n",
      "Epoch 21/50\n",
      "20/20 - 0s - loss: 0.4126 - accuracy: 0.8958 - val_loss: 0.3131 - val_accuracy: 0.9167 - 45ms/epoch - 2ms/step\n",
      "Epoch 22/50\n",
      "20/20 - 0s - loss: 0.3965 - accuracy: 0.8958 - val_loss: 0.3011 - val_accuracy: 0.9167 - 57ms/epoch - 3ms/step\n",
      "Epoch 23/50\n",
      "20/20 - 0s - loss: 0.3824 - accuracy: 0.9062 - val_loss: 0.2941 - val_accuracy: 0.8750 - 48ms/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "20/20 - 0s - loss: 0.3688 - accuracy: 0.9062 - val_loss: 0.2863 - val_accuracy: 0.8750 - 56ms/epoch - 3ms/step\n",
      "Epoch 25/50\n",
      "20/20 - 0s - loss: 0.3556 - accuracy: 0.9167 - val_loss: 0.2724 - val_accuracy: 0.8750 - 50ms/epoch - 2ms/step\n",
      "Epoch 26/50\n",
      "20/20 - 0s - loss: 0.3431 - accuracy: 0.9167 - val_loss: 0.2656 - val_accuracy: 0.8750 - 53ms/epoch - 3ms/step\n",
      "Epoch 27/50\n",
      "20/20 - 0s - loss: 0.3318 - accuracy: 0.9167 - val_loss: 0.2579 - val_accuracy: 0.8750 - 45ms/epoch - 2ms/step\n",
      "Epoch 28/50\n",
      "20/20 - 0s - loss: 0.3208 - accuracy: 0.9271 - val_loss: 0.2517 - val_accuracy: 0.8750 - 52ms/epoch - 3ms/step\n",
      "Epoch 29/50\n",
      "20/20 - 0s - loss: 0.3099 - accuracy: 0.9167 - val_loss: 0.2446 - val_accuracy: 0.8750 - 50ms/epoch - 2ms/step\n",
      "Epoch 30/50\n",
      "20/20 - 0s - loss: 0.2998 - accuracy: 0.9167 - val_loss: 0.2384 - val_accuracy: 0.8750 - 50ms/epoch - 3ms/step\n",
      "Epoch 31/50\n",
      "20/20 - 0s - loss: 0.2903 - accuracy: 0.9271 - val_loss: 0.2352 - val_accuracy: 0.9167 - 60ms/epoch - 3ms/step\n",
      "Epoch 32/50\n",
      "20/20 - 0s - loss: 0.2813 - accuracy: 0.9271 - val_loss: 0.2297 - val_accuracy: 0.9167 - 49ms/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "20/20 - 0s - loss: 0.2726 - accuracy: 0.9375 - val_loss: 0.2226 - val_accuracy: 0.9583 - 68ms/epoch - 3ms/step\n",
      "Epoch 34/50\n",
      "20/20 - 0s - loss: 0.2651 - accuracy: 0.9375 - val_loss: 0.2179 - val_accuracy: 0.9583 - 74ms/epoch - 4ms/step\n",
      "Epoch 35/50\n",
      "20/20 - 0s - loss: 0.2564 - accuracy: 0.9375 - val_loss: 0.2084 - val_accuracy: 0.9583 - 58ms/epoch - 3ms/step\n",
      "Epoch 36/50\n",
      "20/20 - 0s - loss: 0.2491 - accuracy: 0.9375 - val_loss: 0.2038 - val_accuracy: 0.9583 - 58ms/epoch - 3ms/step\n",
      "Epoch 37/50\n",
      "20/20 - 0s - loss: 0.2410 - accuracy: 0.9479 - val_loss: 0.1928 - val_accuracy: 0.9167 - 56ms/epoch - 3ms/step\n",
      "Epoch 38/50\n",
      "20/20 - 0s - loss: 0.2364 - accuracy: 0.9479 - val_loss: 0.1909 - val_accuracy: 0.9583 - 48ms/epoch - 2ms/step\n",
      "Epoch 39/50\n",
      "20/20 - 0s - loss: 0.2293 - accuracy: 0.9479 - val_loss: 0.1851 - val_accuracy: 0.9583 - 49ms/epoch - 2ms/step\n",
      "Epoch 40/50\n",
      "20/20 - 0s - loss: 0.2246 - accuracy: 0.9479 - val_loss: 0.1822 - val_accuracy: 0.9583 - 48ms/epoch - 2ms/step\n",
      "Epoch 41/50\n",
      "20/20 - 0s - loss: 0.2166 - accuracy: 0.9479 - val_loss: 0.1760 - val_accuracy: 0.9583 - 58ms/epoch - 3ms/step\n",
      "Epoch 42/50\n",
      "20/20 - 0s - loss: 0.2125 - accuracy: 0.9375 - val_loss: 0.1752 - val_accuracy: 0.9583 - 56ms/epoch - 3ms/step\n",
      "Epoch 43/50\n",
      "20/20 - 0s - loss: 0.2040 - accuracy: 0.9375 - val_loss: 0.1679 - val_accuracy: 0.9583 - 80ms/epoch - 4ms/step\n",
      "Epoch 44/50\n",
      "20/20 - 0s - loss: 0.1987 - accuracy: 0.9479 - val_loss: 0.1621 - val_accuracy: 0.9583 - 109ms/epoch - 5ms/step\n",
      "Epoch 45/50\n",
      "20/20 - 0s - loss: 0.1924 - accuracy: 0.9479 - val_loss: 0.1559 - val_accuracy: 0.9583 - 108ms/epoch - 5ms/step\n",
      "Epoch 46/50\n",
      "20/20 - 0s - loss: 0.1867 - accuracy: 0.9583 - val_loss: 0.1531 - val_accuracy: 0.9583 - 93ms/epoch - 5ms/step\n",
      "Epoch 47/50\n",
      "20/20 - 0s - loss: 0.1815 - accuracy: 0.9583 - val_loss: 0.1462 - val_accuracy: 0.9583 - 104ms/epoch - 5ms/step\n",
      "Epoch 48/50\n",
      "20/20 - 0s - loss: 0.1785 - accuracy: 0.9583 - val_loss: 0.1344 - val_accuracy: 1.0000 - 104ms/epoch - 5ms/step\n",
      "Epoch 49/50\n",
      "20/20 - 0s - loss: 0.1710 - accuracy: 0.9688 - val_loss: 0.1340 - val_accuracy: 1.0000 - 104ms/epoch - 5ms/step\n",
      "Epoch 50/50\n",
      "20/20 - 0s - loss: 0.1657 - accuracy: 0.9688 - val_loss: 0.1338 - val_accuracy: 1.0000 - 116ms/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "Verbose = 2\n",
    "Batch_size = 5\n",
    "Epochs = 50\n",
    "Val_split = 0.20\n",
    "history = model.fit(X_train,y_train,batch_size=Batch_size,epochs=Epochs,verbose=Verbose,validation_split=Val_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff0945",
   "metadata": {},
   "source": [
    "## Accuracy improvement Graph\n",
    "This graph shows how to accuracy changed after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c806ea7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history)[\"accuracy\"].plot(figsize=(8, 5))\n",
    "plt.title(\"Accuracy improvements with Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0583b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1387 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13865311443805695, 0.9666666388511658]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
